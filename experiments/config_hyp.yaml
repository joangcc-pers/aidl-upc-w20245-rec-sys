experiments:

  model_graph_with_embeddings:
    model_name: "graph_with_embeddings"
    model_params:
      epochs: 5
      optimizer: "Adam"
      num_iterations: 1
      embedding_dim: 64
      hidden_dim: 100
      shuffle: False
      batch_size: 50
    data_params:
      input_folder_path: "data/raw/"
      output_folder_artifacts: "experiments/graph_with_embeddings/"
    preprocessing:
      start_month: '2019-10'
      end_month: '2019-10'
      test_sessions_first_n: 500000
      limit_to_view_event: True
      drop_listwise_nulls: True
      min_products_per_session: 3
      normalization_method: 'zscore'
      train_split: 0.8
      val_split: 0.1
      test_split: 0.1
      split_method: 'temporal'
    evaluation:
      top_k: [1, 5, 10, 20]

  model_graph_with_embeddings_and_attention:
    model_name: "graph_with_embeddings_and_attention"
    model_params:
      epochs: 5
      optimizer: "Adam"
      num_iterations: 1
      embedding_dim: 64
      hidden_dim: 100
      shuffle: False
      batch_size: 50
    data_params:
      input_folder_path: "data/raw/"
      output_folder_artifacts: "experiments/graph_with_embeddings_and_attention/"
    preprocessing:
      start_month: '2019-10'
      end_month: '2019-10'
      test_sessions_first_n: 500000
      limit_to_view_event: True
      drop_listwise_nulls: True
      min_products_per_session: 3
      normalization_method: 'zscore'
      train_split: 0.8
      val_split: 0.1
      test_split: 0.1
      split_method: 'temporal'
    evaluation:
      top_k: [1, 5, 10, 20]

  model_graph_with_embeddings_and_attentional_aggregation:
    model_name: "graph_with_embeddings_and_attentional_aggregation"
    model_params:
      epochs: 5
      optimizer: "Adam"
      num_iterations: 1
      embedding_dim: 64
      hidden_dim: 100
      batch_size: 50
      shuffle: False
    data_params:
      input_folder_path: "data/raw/"
      output_folder_artifacts: "experiments/graph_with_embeddings_and_attentional_aggregation/"
    preprocessing:
      start_month: '2019-10'
      end_month: '2019-10'
      test_sessions_first_n: 500000
      limit_to_view_event: True
      drop_listwise_nulls: True
      min_products_per_session: 3
      normalization_method: 'zscore'
      train_split: 0.8
      val_split: 0.1
      test_split: 0.1
      split_method: 'temporal'
    evaluation:
      top_k: [1, 5, 10, 20]

  model_graph_with_encoding_and_attentional_aggregation:
    model_name: "graph_with_encoding_and_attentional_aggregation"
    model_params:
      initial_dimension_dim: 128 
      num_layers: 5
      num_iterations: 1
      hidden_units: 256
      hidden_dim: 100
      optimizer: "Adam"
      epochs: 5
      batch_size: 50
    data_params:
      input_folder_path: "data/raw/"
      output_folder_artifacts: "experiments/model_graph_with_encoding_and_attentional_aggregation/"
    preprocessing:
      start_month: '2019-10'
      end_month: '2019-10'
      test_sessions_first_n: 500000
      limit_to_view_event: True
      drop_listwise_nulls: True
      min_products_per_session: 3
      normalization_method: 'zscore'
      train_split: 0.8
      val_split: 0.1
      test_split: 0.1
      split_method: 'temporal'
    evaluation:
      top_k: [1, 5, 10, 20]

  model_graph_with_attention:
    model_name: "simple_sr_gnn_attn"
    model_params:
      epochs: 50
      optimizer: "Adam"
      num_iterations: 1
      embedding_dim: 64
      hidden_dim: 100
      shuffle: False
      batch_size: 50
    data_params:
      input_folder_path: "data/raw/"
      output_folder_artifacts: "experiments/model_graph_with_attention/"
    preprocessing:
      start_month: '2019-10'
      end_month: '2019-10'
      test_sessions_first_n: 100000
      limit_to_view_event: True
      drop_listwise_nulls: True
      min_products_per_session: 3
      normalization_method: 'zscore'
      train_split: 0.8
      val_split: 0.1
      test_split: 0.1
      split_method: 'temporal'
    evaluation:
      top_k: [1, 5, 10, 20]